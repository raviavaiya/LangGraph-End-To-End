{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346dc5aa",
   "metadata": {},
   "source": [
    "# Tools and Agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f808e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5b8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8411e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üëã  How can I help you today? üòä\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_time': 0.027272727, 'prompt_time': 0.001912157, 'queue_time': 0.232688465, 'total_time': 0.029184884}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9a6cffe4-ee32-43c4-851b-9adf8cb976d7-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hii,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a9fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "enbeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705822b",
   "metadata": {},
   "source": [
    "## Predifine Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fb18f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Model Context Protocol\n",
      "Summary: The Model Context Protocol (MCP) is an open standard developed by the artificial intelligence company Anthropic for enabling large language model (LLM) applications to interact with external tools, systems, and data sources. Designed to standardize context exchange between AI assistants and software environments, MCP provides a model-agnostic interface for reading files, executing functions, and handling contextual prompts. It was officially announced and open-sourced by Anthropic in November 2024, with subsequent adoption by major AI providers including OpenAI and Google DeepMind.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-augmented generation (RAG) is a technique that enables generative artificial intelligence (Gen AI) models to retrieve and incorporate new information. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to supplement information from its pre-existing training data. This allows LLMs to use domain-specific and/or updated information. Use cases include providing chatbot access to internal company data or generating responses based on authoritative sources.\n",
      "RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have led to real-world issues like chatbots inventing policies or lawyers citing nonexistent legal cases.\n",
      "By dynamically retrieving information, RAG enables AI to provide more accurate responses without frequent retraining. According to IBM, \"RAG also reduces the need for users to continuously train the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting.\"\n",
      "Beyond efficiency gains, RAG also allows LLMs to include source references in their responses, enabling users to verify information by reviewing cited documents or original sources. This can provide greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\n",
      "The term \"retrieval-augmented generation\" (RAG) was first introduced in 2020 by Douwe Kiela, Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, and Sebastian Riedel in their research paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, at Meta.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "wikipedia_api = WikipediaAPIWrapper()\n",
    "wiki = WikipediaQueryRun(api_wrapper=wikipedia_api)\n",
    "print(wiki.run({\"query\": \"Langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c8d6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=xVGQrltjaRs&pp=ygUMc3Vubnkgc2F2aXRh', 'https://www.youtube.com/watch?v=m2VaGqZFNlM&pp=ygUMc3Vubnkgc2F2aXRh']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n",
    "youtube = YouTubeSearchTool()\n",
    "print(youtube.run(\"sunny savita\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "893a9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Portfolio - Ravi Avaiya', 'url': 'https://raviavaiya-portfolio.vercel.app/project-details.html', 'content': \"I'm Ravi Avaiya, a dedicated web developer with a passion for crafting exceptional digital experiences. With expertise in a variety of technologies, I\", 'score': 0.76617163}, {'title': 'Ravi Avaiya | Portfolio', 'url': 'https://raviavaiya-portfolio.netlify.app/', 'content': \"I'm Ravi Avaiya, a dedicated Data Scientist with a passion for crafting exceptional digital experiences.\\n        With expertise in a variety of technologies, I specialize in Data Science. [...] Ravi Avaiya\\n\\nI'm a Data Scientist\\n\\nAbout Me\\n\\nPassionate Data Scientist Crafting Engaging Digital Experiences\\n\\nHappy Clients Successfully delivered quality services to satisfied clients.\\n\\nProjects Completed diverse projects with excellence and precision.\\n\\nYears of experience Bringing two years of expertise in the industry.\\n\\nAwards Recognized with five prestigious awards for outstanding work.\\n\\nMy Resume [...] As a chatbot developer, I build AI-driven chatbots that offer efficient, accurate,\\n                and personalized user experiences across various platforms, ensuring smooth interaction and customer\\n                satisfaction.\\n\\nMy Skills\\n\\nUnleashing the Power of Skills: Showcasing a Diverse Arsenal of Expertise, Innovation, and\\n            Problem-Solving. Explore a Spectrum of Proficiencies that Drive Results and Fuel Success\\n\\nProjects\", 'score': 0.755078}, {'title': 'Ravi Avaiya raviavaiya - GitHub', 'url': 'https://github.com/raviavaiya', 'content': 'You must be logged in to block users.\\n\\nContact GitHub support about this user‚Äôs behavior.\\n        Learn more about reporting abuse.\\n\\n‡§®‡§Æ‡§∏‡•ç‡§§‡•á üôèüèª, Hi there üëã I am Ravi Avaiya!\\n\\n\\n\\nüî≠ I‚Äôm currently working on AI/ML Projects\\n\\nüå± I‚Äôm currently learning Python | FastAPI | LangChain | Prompt Engineering\\n\\nüí¨ Ask me about Python, AI, Data Science, Machine Learning, LangChain, RAG\\n\\nüì´ How to reach me:\\n\\n‚ö° Fun fact: I love building communities and mentoring beginners!\\n\\nüõ†Ô∏è Tech Stack\\n\\nüë®\\u200düíª Languages [...] Navigation Menu\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\nProvide feedback\\n\\nWe read every piece of feedback, and take your input very seriously.\\n\\nSaved searches\\n\\nUse saved searches to filter your results more quickly\\n\\nTo see all available qualifiers, see our documentation.\\n\\n\\n\\nRavi Avaiya\\n        \\n\\n          raviavaiya\\n\\nBlock or report raviavaiya\\n\\nPrevent this user from interacting with your repositories and sending you notifications.\\n          Learn more about blocking users. [...] Vibe Coding.....\\n\\nHTML\\n\\nFooter\\n\\nFooter navigation', 'score': 0.68496037}, {'title': 'Ravi Avaiya | Novice - Kaggle', 'url': 'https://www.kaggle.com/raviavaiya', 'content': 'Results-driven Machine Learning Intern with expertise in Generative AI, Natural Language Processing (NLP), and predictive modeling.', 'score': 0.61779}, {'title': 'Ravi Avaiya - Surat, Gujarat, India | Professional Profile - LinkedIn', 'url': 'https://in.linkedin.com/in/ravi-avaiya-8796262a4', 'content': \"Student at Uka Tarsadia University ¬∑ Education: Uka Tarsadia University ¬∑ Location: Surat ¬∑ 1 connection on LinkedIn. View Ravi Avaiya's profile on LinkedIn\", 'score': 0.6158511}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import  TavilySearchResults\n",
    "search = TavilySearchResults()\n",
    "print(search.invoke({\"query\":\"Ravi Avaiya\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b94ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgreph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
