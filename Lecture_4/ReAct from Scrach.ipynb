{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91cd4076",
   "metadata": {},
   "source": [
    "# What is a ReAct Agent ( Reasoning & Acting )?\n",
    "\n",
    "- A ReAct agent is an AI agent that utilizes the \"reasoning and acting\" (ReAct) framework to integrate chain of thought (CoT) reasoning with external tool use. This framework enhances the capabilities of a large language model (LLM) to handle complex tasks and decision-making in agentic workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41e702",
   "metadata": {},
   "source": [
    "# Overview of ReAct Agent Design\n",
    "\n",
    "ReAct agents bring a new approach to AI by combining reasoning and action in a continuous cycle. As we learned previously, traditional AI systems separate decision-making from execution, whereas ReAct agents are designed to think and act in a loop. They take in a task, break it down, use external resources to gather information, and adapt based on what they learn. This makes them ideal for handling dynamic tasks that require constant adjustment and interaction with external environments. A 1000-foot overview of the agent architecture is shown above. Let’s break it down one by one:\n",
    "\n",
    "- Input: \n",
    "    The agent starts by receiving a task in natural language. This task goes into the core language model (LLM), like Gemini Pro, which interprets what needs to be done. Thus, the LLM acts as the agent’s “brain,” setting the task in motion. The task is provided by the user. The goal here for the agent is to leverage the tools available at hand to solve the task.\n",
    "\n",
    "- Reasoning:\n",
    "     The LLM analyzes the task and breaks it down into steps. It plans which actions to take and decides how to approach the problem based on available information and tools.\n",
    "\n",
    "- Action with External Environments:\n",
    "     In our current setup, the agent has access to two main environments — Google Search and Wikipedia. Using specific tools connected via APIs, it can look up information on Google for the latest updates or gather facts from Wikipedia. Each action the agent takes depends on what it determines to be the best source for the task. By connecting to these external environments, the agent can quickly find relevant information or get additional context.\n",
    "\n",
    "- Observation and Memory:\n",
    "     After executing each action, the agent observes the results and saves relevant information in its memory. This tracing allows it to keep track of past actions and build on previous observations, so it doesn’t repeat itself or lose context. Each new piece of information enriches the agent’s understanding of the task, making future actions more informed.\n",
    "     \n",
    "- Feedback Loop:\n",
    "     The agent cycles through reasoning, action, and observation steps continuously. Every time it gathers new information, it goes back to the reasoning stage, where the LLM considers the updated knowledge. This iterative loop helps the agent refine its approach and stay aligned with the task. The reasoning loop can be either constrained based on an end condition or capped by max iterations. Note that we leverage past observations here from the memory component.\n",
    "\n",
    "- Response:\n",
    "     Finally, once it has gathered enough information and reached a solid understanding, the agent generates a response based on all the information it has collected and refined over multiple cycles. Again, this can be solely decided by the LLM or based on an end condition, or we may fail to arrive at an outcome given the constrained number of iterations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
